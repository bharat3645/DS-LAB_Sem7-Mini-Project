{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” Crime Analytics - Advanced Data Science Project\n",
    "## Missing Persons & Juvenile Crimes Analysis (2017-2022)\n",
    "\n",
    "This notebook implements comprehensive data science analysis including:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Regression Models\n",
    "- Classification Models\n",
    "- Clustering Analysis\n",
    "- Deep Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas numpy matplotlib seaborn plotly scikit-learn xgboost lightgbm tensorflow\n",
    "\n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 2: Upload Data Files\n",
    "\n",
    "Upload the following CSV files:\n",
    "1. `districtwise-missing-persons-2017-2022.csv`\n",
    "2. `districtwise-ipc-crime-by-juveniles-2017-onwards.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload the CSV files...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\nâœ… Files uploaded:\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 3: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load datasets\n",
    "missing_df = pd.read_csv('districtwise-missing-persons-2017-2022.csv')\n",
    "crimes_df = pd.read_csv('districtwise-ipc-crime-by-juveniles-2017-onwards.csv')\n",
    "\n",
    "print(\"ðŸ“Š DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMissing Persons Dataset:\")\n",
    "print(f\"  Shape: {missing_df.shape}\")\n",
    "print(f\"  Years: {sorted(missing_df['year'].unique())}\")\n",
    "print(f\"  States: {missing_df['state_name'].nunique()}\")\n",
    "print(f\"  Districts: {missing_df['district_name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nJuvenile Crimes Dataset:\")\n",
    "print(f\"  Shape: {crimes_df.shape}\")\n",
    "print(f\"  Years: {sorted(crimes_df['year'].unique())}\")\n",
    "print(f\"  States: {crimes_df['state_name'].nunique()}\")\n",
    "print(f\"  Districts: {crimes_df['district_name'].nunique()}\")\n",
    "\n",
    "print(\"\\nâœ… Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Missing Persons Data\n",
    "missing_clean = missing_df.copy()\n",
    "numeric_cols = missing_clean.select_dtypes(include=[np.number]).columns\n",
    "missing_clean[numeric_cols] = missing_clean[numeric_cols].fillna(0)\n",
    "\n",
    "# Create aggregated features\n",
    "missing_clean['male_total'] = (missing_clean['male_below_5_years'] + \n",
    "                                missing_clean['male_5_to_14_years'] + \n",
    "                                missing_clean['male_14_to_18_years'] + \n",
    "                                missing_clean['male_18_to_30_years'] + \n",
    "                                missing_clean['male_30_to_45_years'] + \n",
    "                                missing_clean['male_45_to_60_years'] + \n",
    "                                missing_clean['male_60_years_and_above'])\n",
    "\n",
    "missing_clean['female_total'] = (missing_clean['female_below_5_years'] + \n",
    "                                  missing_clean['female_5_to_14_years'] + \n",
    "                                  missing_clean['female_14_to_18_years'] + \n",
    "                                  missing_clean['female_18_to_30_years'] + \n",
    "                                  missing_clean['female_30_to_45_years'] + \n",
    "                                  missing_clean['female_45_to_60_years'] + \n",
    "                                  missing_clean['female_60_years_and_above'])\n",
    "\n",
    "missing_clean['transgender_total'] = (missing_clean['trangender_below_5_years'] + \n",
    "                                       missing_clean['trangender_5_to_14_years'] + \n",
    "                                       missing_clean['trangender_14_to_18_years'] + \n",
    "                                       missing_clean['trangender_18_to_30_years'] + \n",
    "                                       missing_clean['trangender_30_to_45_years'] + \n",
    "                                       missing_clean['trangender_45_to_60_years'] + \n",
    "                                       missing_clean['transgender_60_years_and_above'])\n",
    "\n",
    "missing_clean['total_missing'] = (missing_clean['male_total'] + \n",
    "                                   missing_clean['female_total'] + \n",
    "                                   missing_clean['transgender_total'])\n",
    "\n",
    "# Clean Crimes Data\n",
    "crimes_clean = crimes_df.copy()\n",
    "numeric_cols = crimes_clean.select_dtypes(include=[np.number]).columns\n",
    "crimes_clean[numeric_cols] = crimes_clean[numeric_cols].fillna(0)\n",
    "\n",
    "crime_cols = [col for col in crimes_clean.columns if col not in \n",
    "              ['id', 'year', 'state_name', 'state_code', 'district_name', \n",
    "               'district_code', 'registration_circles']]\n",
    "\n",
    "crimes_clean['total_crimes'] = crimes_clean[crime_cols].sum(axis=1)\n",
    "\n",
    "print(\"âœ… Data preprocessing complete!\")\n",
    "print(f\"\\nMissing Persons - Total Missing: {missing_clean['total_missing'].sum():,.0f}\")\n",
    "print(f\"Juvenile Crimes - Total Crimes: {crimes_clean['total_crimes'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 5: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly trends for Missing Persons\n",
    "yearly_missing = missing_clean.groupby('year')['total_missing'].sum().reset_index()\n",
    "\n",
    "fig = px.line(yearly_missing, x='year', y='total_missing',\n",
    "              title='Total Missing Persons Over Years',\n",
    "              labels={'year': 'Year', 'total_missing': 'Total Missing Persons'},\n",
    "              markers=True)\n",
    "fig.update_traces(line_color='#e74c3c', line_width=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "gender_data = pd.DataFrame({\n",
    "    'Gender': ['Male', 'Female', 'Transgender'],\n",
    "    'Count': [\n",
    "        missing_clean['male_total'].sum(),\n",
    "        missing_clean['female_total'].sum(),\n",
    "        missing_clean['transgender_total'].sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "fig = px.pie(gender_data, values='Count', names='Gender',\n",
    "             title='Gender Distribution of Missing Persons',\n",
    "             color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 states - Missing Persons\n",
    "state_missing = missing_clean.groupby('state_name')['total_missing'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "fig = px.bar(x=state_missing.values, y=state_missing.index, orientation='h',\n",
    "             title='Top 10 States - Missing Persons',\n",
    "             labels={'x': 'Total Missing', 'y': 'State'},\n",
    "             color=state_missing.values,\n",
    "             color_continuous_scale='Reds')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly trends for Crimes\n",
    "yearly_crimes = crimes_clean.groupby('year')['total_crimes'].sum().reset_index()\n",
    "\n",
    "fig = px.line(yearly_crimes, x='year', y='total_crimes',\n",
    "              title='Total Juvenile Crimes Over Years',\n",
    "              labels={'year': 'Year', 'total_crimes': 'Total Crimes'},\n",
    "              markers=True)\n",
    "fig.update_traces(line_color='#2ecc71', line_width=3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Step 6: Machine Learning - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# Prepare data for regression\n",
    "age_cols = [col for col in missing_clean.columns if 'male_' in col or 'female_' in col or 'trangender' in col]\n",
    "age_cols = [col for col in age_cols if col not in ['male_total', 'female_total', 'transgender_total']]\n",
    "\n",
    "X = missing_clean[age_cols].fillna(0)\n",
    "y = missing_clean['total_missing']\n",
    "\n",
    "# Remove rows where target is 0\n",
    "mask = y > 0\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"ðŸ“Š REGRESSION: Predicting Total Missing Persons\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {len(X.columns)}\")\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'RÂ² Score': r2,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae\n",
    "    })\n",
    "    \n",
    "    print(f\"  RÂ² Score: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values('RÂ² Score', ascending=False)\n",
    "print(\"\\nðŸ“Š MODEL COMPARISON:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 7: Machine Learning - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create classification target (High vs Low crime)\n",
    "crimes_for_class = crimes_clean.copy()\n",
    "crime_threshold = crimes_for_class['total_crimes'].median()\n",
    "crimes_for_class['crime_level'] = (crimes_for_class['total_crimes'] > crime_threshold).astype(int)\n",
    "\n",
    "# Select features\n",
    "crime_feature_cols = [col for col in crimes_for_class.columns \n",
    "                      if col not in ['id', 'year', 'state_name', 'state_code', \n",
    "                                    'district_name', 'district_code', 'registration_circles',\n",
    "                                    'total_crimes', 'crime_level']]\n",
    "\n",
    "X_class = crimes_for_class[crime_feature_cols[:20]].fillna(0)\n",
    "y_class = crimes_for_class['crime_level']\n",
    "\n",
    "# Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, \n",
    "                                                              test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"ðŸŽ¯ CLASSIFICATION: High vs Low Crime Districts\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(X_train_c)}\")\n",
    "print(f\"Test samples: {len(X_test_c)}\")\n",
    "print(f\"Features: {len(X_class.columns)}\")\n",
    "\n",
    "# Train models\n",
    "class_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, max_depth=5, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "class_results = []\n",
    "for name, model in class_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_c, y_train_c)\n",
    "    \n",
    "    y_pred = model.predict(X_test_c)\n",
    "    accuracy = accuracy_score(y_test_c, y_pred)\n",
    "    \n",
    "    class_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display results\n",
    "class_results_df = pd.DataFrame(class_results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nðŸ“Š MODEL COMPARISON:\")\n",
    "print(class_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ Step 8: Machine Learning - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Aggregate by state\n",
    "state_agg = crimes_clean.groupby('state_name')['total_crimes'].sum().reset_index()\n",
    "missing_state_agg = missing_clean.groupby('state_name')['total_missing'].sum().reset_index()\n",
    "\n",
    "state_combined = pd.merge(state_agg, missing_state_agg, on='state_name')\n",
    "\n",
    "# Prepare features\n",
    "X_cluster = state_combined[['total_crimes', 'total_missing']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(\"ðŸŒ CLUSTERING: State-level Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Try different number of clusters\n",
    "silhouette_scores = []\n",
    "K_range = range(3, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"K={k}: Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# Use best K\n",
    "best_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nâœ… Best K = {best_k}\")\n",
    "\n",
    "# Final clustering\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "state_combined['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize\n",
    "fig = px.scatter(state_combined, x='total_crimes', y='total_missing',\n",
    "                 color='cluster', hover_data=['state_name'],\n",
    "                 title=f'State Clustering (K={best_k})',\n",
    "                 labels={'total_crimes': 'Total Crimes', 'total_missing': 'Total Missing'},\n",
    "                 size='total_crimes')\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Cluster Distribution:\")\n",
    "print(state_combined['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 9: Deep Learning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"ðŸ§  DEEP LEARNING: Neural Network Regression\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data (use same X, y from regression)\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"Training neural network...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_dl = model.predict(X_test_scaled, verbose=0).flatten()\n",
    "r2_dl = r2_score(y_test, y_pred_dl)\n",
    "rmse_dl = np.sqrt(mean_squared_error(y_test, y_pred_dl))\n",
    "\n",
    "print(f\"\\nâœ… Deep Learning Results:\")\n",
    "print(f\"  RÂ² Score: {r2_dl:.4f}\")\n",
    "print(f\"  RMSE: {rmse_dl:.2f}\")\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['mae'], label='Training MAE')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.set_title('Model MAE')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‘ Step 10: Summary & Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ“Š PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Datasets Analyzed:\")\n",
    "print(f\"  - Missing Persons: {missing_clean.shape[0]:,} records\")\n",
    "print(f\"  - Juvenile Crimes: {crimes_clean.shape[0]:,} records\")\n",
    "print(f\"  - Time Period: 2017-2022 (6 years)\")\n",
    "print(f\"  - Geographic Coverage: {missing_clean['state_name'].nunique()} states\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Key Statistics:\")\n",
    "print(f\"  - Total Missing Persons: {missing_clean['total_missing'].sum():,.0f}\")\n",
    "print(f\"  - Total Juvenile Crimes: {crimes_clean['total_crimes'].sum():,.0f}\")\n",
    "print(f\"  - Average Missing per District: {missing_clean['total_missing'].mean():.0f}\")\n",
    "print(f\"  - Average Crimes per District: {crimes_clean['total_crimes'].mean():.0f}\")\n",
    "\n",
    "print(\"\\nðŸ¤– Machine Learning Results:\")\n",
    "print(f\"  - Regression Models Trained: {len(results)}\")\n",
    "print(f\"  - Best Regression RÂ²: {results_df.iloc[0]['RÂ² Score']:.4f}\")\n",
    "print(f\"  - Classification Models Trained: {len(class_results)}\")\n",
    "print(f\"  - Best Classification Accuracy: {class_results_df.iloc[0]['Accuracy']:.4f}\")\n",
    "print(f\"  - Clustering: {best_k} distinct state patterns identified\")\n",
    "\n",
    "print(\"\\nðŸŽ“ Techniques Implemented:\")\n",
    "print(\"  âœ… Exploratory Data Analysis\")\n",
    "print(\"  âœ… Data Preprocessing & Feature Engineering\")\n",
    "print(\"  âœ… Regression (8 algorithms)\")\n",
    "print(\"  âœ… Classification (5 algorithms)\")\n",
    "print(\"  âœ… Clustering (K-Means)\")\n",
    "print(\"  âœ… Deep Learning (Neural Networks)\")\n",
    "print(\"  âœ… Interactive Visualizations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ’¡ Next Steps:\")\n",
    "print(\"  1. Deploy the Streamlit dashboard for interactive exploration\")\n",
    "print(\"  2. Perform time series forecasting\")\n",
    "print(\"  3. Add geospatial visualizations\")\n",
    "print(\"  4. Implement explainable AI techniques\")\n",
    "print(\"  5. Create automated reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸš€ Deploy Streamlit Dashboard\n",
    "\n",
    "To run the interactive Streamlit dashboard:\n",
    "\n",
    "```bash\n",
    "# Install streamlit-tunnel for Colab\n",
    "!pip install streamlit-tunnel\n",
    "\n",
    "# Run the app (upload streamlit_app.py first)\n",
    "!streamlit run streamlit_app.py &>/dev/null&\n",
    "\n",
    "# Use localtunnel for public URL\n",
    "!npx localtunnel --port 8501\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
